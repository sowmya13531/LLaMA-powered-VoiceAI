# ðŸŽ™ï¸ LLaMA-Powered Offline Voice AI Assistant
A fully offline, privacy-first Voice AI Assistant built using LLaMA 3.2 via ollama, capable of real-time speech interaction, conversational memory, and voice responses â€” all running locally without cloud-based LLM APIs.

## ðŸš€ Project Overview
This project implements an end-to-end Voice AI pipeline that allows users to speak naturally, receive intelligent responses from a local LLM, and experience continuous conversation with short-term memory.

> Key Idea:
Replicate how humans converse â€” listen â†’ think â†’ respond â†’ remember â€” using open-source tools and a local Large Language Model.


## ðŸ§  Key Features

- ðŸŽ¤ Real-time Speech-to-Text (STT)
- ðŸ§  Local LLaMA 3.2 inference via Ollama
- ðŸ” Conversational Memory (context-aware replies)
- ðŸ—£ï¸ Text-to-Speech (TTS) responses
- ðŸ” Offline-first & privacy-preserving architecture
- ðŸ§© Modular and extensible design

### ðŸ—ï¸ System Architecture

```
User Speech
   â†“
Speech-to-Text (STT)
   â†“
Conversation Memory (Context)
   â†“
LLaMA 3.2 (via Ollama)
   â†“
Text-to-Speech (TTS)
   â†“
Voice Response
```

Each component is decoupled, making the system easy to extend or replace.

## ðŸ“ Project Structure

```
LLaMA-powered-VoiceAI/
â”‚
â”œâ”€â”€ main.py        # Orchestrates the full voice-AI loop
â”œâ”€â”€ llm.py         # Handles interaction with LLaMA 3.2 via Ollama
â”œâ”€â”€ memory.py      # Manages conversational context (short-term memory)
â”œâ”€â”€ sst.py         # Speech-to-Text (microphone input)
â”œâ”€â”€ tts.py         # Text-to-Speech (voice output)
â””â”€â”€ README.md
```

## ðŸ“„ Module Explanations

1ï¸âƒ£ sst.py â€” Speech-to-Text (Listening Layer)
- Captures live microphone audio
- Adjusts dynamically for ambient noise
- Converts speech into text commands

## Why this matters:
Ensures the assistant works in real-world environments, not just quiet rooms.

> âš ï¸ Note: Uses Google STT (internet required).
Designed to be easily replaceable with Whisper or Vosk for full offline STT.

2ï¸âƒ£ memory.py â€” Conversational Memory
- Stores recent user and assistant messages
- Maintains a sliding window of the last 6 interactions
- Prevents prompt overload while preserving context

-> Why this matters:
- Without memory, conversations feel robotic.
- With memory, responses feel continuous and intelligent.

3ï¸âƒ£ llm.py â€” Local LLM Inference (Thinking Layer)
- Uses LLaMA 3.2 running locally via Ollama
- Communicates through a subprocess call
- Injects conversation context directly into the prompt

### Why Ollama + subprocess?
- OS-agnostic
- Lightweight integration
- No dependency lock-in
- Optimized local inference

4ï¸âƒ£ tts.py â€” Text-to-Speech (Speaking Layer)
- Converts AI responses into natural voice output
- Tuned speech rate for better human-like delivery

### Why this matters:
Voice UX is critical â€” clarity and pacing improve usability.

5ï¸âƒ£ main.py â€” Orchestrator
- Controls the full conversation loop
- Handles exit commands gracefully
- Manages memory, LLM calls, and voice interaction
- This file ties all intelligence layers together.


## ðŸ” Execution Flow

1. Assistant greets the user
2. Listens for voice input
3. Converts speech â†’ text
4. Appends conversation to memory
5. Sends prompt + context to LLaMA
6. Receives response
7. Converts text â†’ speech
8. Speaks response
9. Repeats until user exits

## ðŸ› ï¸ Installation & Setup

-> Prerequisites
- Python 3.9+
- Microphone
- Ollama installed
- Install Ollama & Model
- ollama pull llama3.2

### Install Python Dependencies
```
pip install speechrecognition pyttsx3 pyaudio
```

> âš ï¸ pyaudio installation may require OS-specific setup.

â–¶ï¸ Run the Assistant

**python main.py**

- Speak naturally â€” say â€œexitâ€, â€œquitâ€, or â€œstopâ€ to end the session.
- ðŸ” Privacy & Offline Design
- No cloud-based LLM APIs
- No data sent to external servers for inference
- LLM runs fully on the local machine


> Ideal for privacy-sensitive environments.

#### ðŸš§ Known Limitations

- Current STT uses Google Speech Recognition (internet required)
- Memory is short-term (in-memory only)


## ðŸŽ¯ Why This Project Matters

- This is not just a chatbot.

It demonstrates:

- End-to-end AI system design
- Real-time voice interaction
- Local LLM deployment
- Conversational memory handling
- Modular, production-ready architecture


ðŸ‘¤ Author

Sowmya Kanithii
Aspiring Machine Learning Engineer | AI Systems Builder
GitHub: (Sowmya)[https://github.com/sowmya13531]

